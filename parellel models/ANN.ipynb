{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import math\n",
    "import gensim\n",
    "from gensim.models import Word2Vec \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(df):\n",
    "\n",
    "    y = df.label.tolist()\n",
    "    X = np.matrix(df.drop(labels = ['label'], axis = 1)).astype(np.float)\n",
    "    print(X.shape)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "   \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "    \n",
    "def precision(y_true, y_pred):\n",
    "    \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    \n",
    "    myPrecision = precision(y_true, y_pred)\n",
    "    myRecall = recall(y_true, y_pred)\n",
    "    return 2*((myPrecision*myRecall)/(myPrecision+myRecall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = [#'/scratch/by8jj/stratified samples/test of test/train/train_11.csv',\n",
    "             #'/scratch/by8jj/stratified samples/test of test/train/train_12.csv',\n",
    "             #'/scratch/by8jj/stratified samples/test of test/train/train_13.csv',\n",
    "             #'/scratch/by8jj/stratified samples/test of test/train/train_14.csv',\n",
    "             #'/scratch/by8jj/stratified samples/test of test/train/train_15.csv',\n",
    "             '/scratch/by8jj/stratified samples/test of test/train/train_16.csv',\n",
    "             '/scratch/by8jj/stratified samples/test of test/train/train_17.csv',\n",
    "             '/scratch/by8jj/stratified samples/test of test/train/train_18.csv',\n",
    "             '/scratch/by8jj/stratified samples/test of test/train/train_19.csv',\n",
    "             '/scratch/by8jj/stratified samples/test of test/train/train_20.csv',\n",
    "             '/scratch/by8jj/stratified samples/test of test/train/train_21.csv',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPath = [#'/scratch/by8jj/stratified samples/test of test/test/test_12.csv',\n",
    "           #'/scratch/by8jj/stratified samples/test of test/test/test_13.csv',\n",
    "           #'/scratch/by8jj/stratified samples/test of test/test/test_14.csv',\n",
    "           #'/scratch/by8jj/stratified samples/test of test/test/test_15.csv',\n",
    "           #'/scratch/by8jj/stratified samples/test of test/test/test_16.csv',\n",
    "            '/scratch/by8jj/stratified samples/test of test/test/test_17.csv',\n",
    "           '/scratch/by8jj/stratified samples/test of test/test/test_18.csv',\n",
    "           '/scratch/by8jj/stratified samples/test of test/test/test_19.csv',\n",
    "           '/scratch/by8jj/stratified samples/test of test/test/test_20.csv',\n",
    "            '/scratch/by8jj/stratified samples/test of test/test/test_21.csv',\n",
    "           '/scratch/by8jj/stratified samples/test of test/test/test_22.csv',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3292475, 73)\n",
      "dim is 73\n",
      "Train on 2304732 samples, validate on 987743 samples\n",
      "Epoch 1/25\n",
      "2304732/2304732 [==============================] - 17s 8us/step - loss: 0.1796 - acc: 0.9395 - f1: 0.9332 - recall: 0.9823 - precision: 0.8896 - val_loss: 0.1253 - val_acc: 0.9521 - val_f1: 0.9465 - val_recall: 0.9893 - val_precision: 0.9077\n",
      "Epoch 2/25\n",
      "2304732/2304732 [==============================] - 17s 7us/step - loss: 0.1291 - acc: 0.9523 - f1: 0.9466 - recall: 0.9902 - precision: 0.9071 - val_loss: 0.1199 - val_acc: 0.9529 - val_f1: 0.9474 - val_recall: 0.9919 - val_precision: 0.9071\n",
      "Epoch 3/25\n",
      "2304732/2304732 [==============================] - 17s 8us/step - loss: 0.1247 - acc: 0.9529 - f1: 0.9473 - recall: 0.9912 - precision: 0.9076 - val_loss: 0.1174 - val_acc: 0.9535 - val_f1: 0.9481 - val_recall: 0.9921 - val_precision: 0.9082\n",
      "Epoch 4/25\n",
      "2304732/2304732 [==============================] - 18s 8us/step - loss: 0.1221 - acc: 0.9534 - f1: 0.9478 - recall: 0.9913 - precision: 0.9084 - val_loss: 0.1152 - val_acc: 0.9536 - val_f1: 0.9482 - val_recall: 0.9924 - val_precision: 0.9082\n",
      "Epoch 5/25\n",
      "2304732/2304732 [==============================] - 18s 8us/step - loss: 0.1202 - acc: 0.9535 - f1: 0.9479 - recall: 0.9910 - precision: 0.9088 - val_loss: 0.1135 - val_acc: 0.9539 - val_f1: 0.9486 - val_recall: 0.9925 - val_precision: 0.9088\n",
      "Epoch 6/25\n",
      "2304732/2304732 [==============================] - 18s 8us/step - loss: 0.1188 - acc: 0.9538 - f1: 0.9482 - recall: 0.9906 - precision: 0.9097 - val_loss: 0.1120 - val_acc: 0.9540 - val_f1: 0.9487 - val_recall: 0.9925 - val_precision: 0.9089\n",
      "Epoch 7/25\n",
      "2304732/2304732 [==============================] - 17s 8us/step - loss: 0.1178 - acc: 0.9540 - f1: 0.9484 - recall: 0.9903 - precision: 0.9103 - val_loss: 0.1111 - val_acc: 0.9541 - val_f1: 0.9487 - val_recall: 0.9925 - val_precision: 0.9090\n",
      "Epoch 8/25\n",
      "2304732/2304732 [==============================] - 18s 8us/step - loss: 0.1170 - acc: 0.9542 - f1: 0.9486 - recall: 0.9902 - precision: 0.9108 - val_loss: 0.1103 - val_acc: 0.9541 - val_f1: 0.9488 - val_recall: 0.9925 - val_precision: 0.9091\n",
      "Epoch 9/25\n",
      "2304732/2304732 [==============================] - 17s 8us/step - loss: 0.1163 - acc: 0.9543 - f1: 0.9488 - recall: 0.9901 - precision: 0.9111 - val_loss: 0.1094 - val_acc: 0.9547 - val_f1: 0.9494 - val_recall: 0.9919 - val_precision: 0.9108\n",
      "Epoch 10/25\n",
      "2304732/2304732 [==============================] - 17s 8us/step - loss: 0.1155 - acc: 0.9545 - f1: 0.9489 - recall: 0.9899 - precision: 0.9116 - val_loss: 0.1090 - val_acc: 0.9552 - val_f1: 0.9498 - val_recall: 0.9908 - val_precision: 0.9124\n",
      "Epoch 11/25\n",
      "2304732/2304732 [==============================] - 16s 7us/step - loss: 0.1150 - acc: 0.9545 - f1: 0.9489 - recall: 0.9895 - precision: 0.9120 - val_loss: 0.1084 - val_acc: 0.9549 - val_f1: 0.9496 - val_recall: 0.9921 - val_precision: 0.9109\n",
      "Epoch 12/25\n",
      "2304732/2304732 [==============================] - 16s 7us/step - loss: 0.1147 - acc: 0.9547 - f1: 0.9491 - recall: 0.9896 - precision: 0.9122 - val_loss: 0.1080 - val_acc: 0.9549 - val_f1: 0.9496 - val_recall: 0.9921 - val_precision: 0.9110\n",
      "Epoch 13/25\n",
      "2304732/2304732 [==============================] - 16s 7us/step - loss: 0.1142 - acc: 0.9548 - f1: 0.9492 - recall: 0.9896 - precision: 0.9124 - val_loss: 0.1077 - val_acc: 0.9549 - val_f1: 0.9496 - val_recall: 0.9922 - val_precision: 0.9110\n",
      "Epoch 14/25\n",
      "2304732/2304732 [==============================] - 16s 7us/step - loss: 0.1140 - acc: 0.9548 - f1: 0.9492 - recall: 0.9895 - precision: 0.9124 - val_loss: 0.1075 - val_acc: 0.9553 - val_f1: 0.9500 - val_recall: 0.9911 - val_precision: 0.9125\n",
      "Epoch 15/25\n",
      "2304732/2304732 [==============================] - 16s 7us/step - loss: 0.1138 - acc: 0.9548 - f1: 0.9492 - recall: 0.9896 - precision: 0.9124 - val_loss: 0.1073 - val_acc: 0.9552 - val_f1: 0.9499 - val_recall: 0.9910 - val_precision: 0.9125\n",
      "Epoch 16/25\n",
      "2304732/2304732 [==============================] - 16s 7us/step - loss: 0.1134 - acc: 0.9549 - f1: 0.9493 - recall: 0.9897 - precision: 0.9125 - val_loss: 0.1071 - val_acc: 0.9550 - val_f1: 0.9497 - val_recall: 0.9922 - val_precision: 0.9111\n",
      "Epoch 17/25\n",
      "2304732/2304732 [==============================] - 16s 7us/step - loss: 0.1134 - acc: 0.9549 - f1: 0.9493 - recall: 0.9898 - precision: 0.9124 - val_loss: 0.1071 - val_acc: 0.9551 - val_f1: 0.9498 - val_recall: 0.9919 - val_precision: 0.9115\n",
      "Epoch 18/25\n",
      "2304732/2304732 [==============================] - 16s 7us/step - loss: 0.1132 - acc: 0.9550 - f1: 0.9494 - recall: 0.9898 - precision: 0.9126 - val_loss: 0.1069 - val_acc: 0.9558 - val_f1: 0.9505 - val_recall: 0.9906 - val_precision: 0.9138\n",
      "Epoch 19/25\n",
      "2304732/2304732 [==============================] - 16s 7us/step - loss: 0.1130 - acc: 0.9550 - f1: 0.9494 - recall: 0.9897 - precision: 0.9127 - val_loss: 0.1067 - val_acc: 0.9552 - val_f1: 0.9499 - val_recall: 0.9921 - val_precision: 0.9115\n",
      "Epoch 20/25\n",
      "2304732/2304732 [==============================] - 16s 7us/step - loss: 0.1129 - acc: 0.9550 - f1: 0.9495 - recall: 0.9898 - precision: 0.9127 - val_loss: 0.1065 - val_acc: 0.9551 - val_f1: 0.9499 - val_recall: 0.9923 - val_precision: 0.9113\n",
      "Epoch 21/25\n",
      "2304732/2304732 [==============================] - 16s 7us/step - loss: 0.1129 - acc: 0.9550 - f1: 0.9495 - recall: 0.9900 - precision: 0.9126 - val_loss: 0.1065 - val_acc: 0.9554 - val_f1: 0.9501 - val_recall: 0.9911 - val_precision: 0.9128\n",
      "Epoch 22/25\n",
      "2304732/2304732 [==============================] - 16s 7us/step - loss: 0.1128 - acc: 0.9551 - f1: 0.9495 - recall: 0.9898 - precision: 0.9128 - val_loss: 0.1064 - val_acc: 0.9554 - val_f1: 0.9501 - val_recall: 0.9919 - val_precision: 0.9121\n",
      "Epoch 23/25\n",
      "2304732/2304732 [==============================] - 16s 7us/step - loss: 0.1126 - acc: 0.9551 - f1: 0.9496 - recall: 0.9898 - precision: 0.9129 - val_loss: 0.1064 - val_acc: 0.9552 - val_f1: 0.9499 - val_recall: 0.9922 - val_precision: 0.9114\n",
      "Epoch 24/25\n",
      "2304732/2304732 [==============================] - 16s 7us/step - loss: 0.1126 - acc: 0.9551 - f1: 0.9496 - recall: 0.9898 - precision: 0.9129 - val_loss: 0.1061 - val_acc: 0.9553 - val_f1: 0.9500 - val_recall: 0.9922 - val_precision: 0.9117\n",
      "Epoch 25/25\n",
      "2304732/2304732 [==============================] - 16s 7us/step - loss: 0.1125 - acc: 0.9551 - f1: 0.9496 - recall: 0.9898 - precision: 0.9129 - val_loss: 0.1061 - val_acc: 0.9556 - val_f1: 0.9503 - val_recall: 0.9911 - val_precision: 0.9131\n",
      "(2222644, 73)\n",
      "(3687944, 73)\n",
      "dim is 73\n",
      "Train on 2581560 samples, validate on 1106384 samples\n",
      "Epoch 1/25\n",
      "2581560/2581560 [==============================] - 18s 7us/step - loss: 0.1739 - acc: 0.9396 - f1: 0.9328 - recall: 0.9841 - precision: 0.8875 - val_loss: 0.1268 - val_acc: 0.9492 - val_f1: 0.9430 - val_recall: 0.9903 - val_precision: 0.9005\n",
      "Epoch 2/25\n",
      "2581560/2581560 [==============================] - 18s 7us/step - loss: 0.1284 - acc: 0.9500 - f1: 0.9438 - recall: 0.9903 - precision: 0.9019 - val_loss: 0.1208 - val_acc: 0.9501 - val_f1: 0.9441 - val_recall: 0.9923 - val_precision: 0.9008\n",
      "Epoch 3/25\n",
      "2581560/2581560 [==============================] - 18s 7us/step - loss: 0.1244 - acc: 0.9506 - f1: 0.9444 - recall: 0.9901 - precision: 0.9033 - val_loss: 0.1180 - val_acc: 0.9504 - val_f1: 0.9445 - val_recall: 0.9931 - val_precision: 0.9008\n",
      "Epoch 4/25\n",
      "2581560/2581560 [==============================] - 18s 7us/step - loss: 0.1222 - acc: 0.9510 - f1: 0.9448 - recall: 0.9889 - precision: 0.9049 - val_loss: 0.1165 - val_acc: 0.9519 - val_f1: 0.9460 - val_recall: 0.9930 - val_precision: 0.9036\n",
      "Epoch 5/25\n",
      "2581560/2581560 [==============================] - 19s 7us/step - loss: 0.1212 - acc: 0.9514 - f1: 0.9452 - recall: 0.9879 - precision: 0.9064 - val_loss: 0.1154 - val_acc: 0.9520 - val_f1: 0.9461 - val_recall: 0.9928 - val_precision: 0.9041\n",
      "Epoch 6/25\n",
      "2581560/2581560 [==============================] - 20s 8us/step - loss: 0.1182 - acc: 0.9520 - f1: 0.9457 - recall: 0.9852 - precision: 0.9096 - val_loss: 0.1128 - val_acc: 0.9533 - val_f1: 0.9474 - val_recall: 0.9925 - val_precision: 0.9067\n",
      "Epoch 11/25\n",
      "2581560/2581560 [==============================] - 20s 8us/step - loss: 0.1177 - acc: 0.9520 - f1: 0.9456 - recall: 0.9852 - precision: 0.9096 - val_loss: 0.1124 - val_acc: 0.9531 - val_f1: 0.9473 - val_recall: 0.9924 - val_precision: 0.9064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25\n",
      "2581560/2581560 [==============================] - 20s 8us/step - loss: 0.1174 - acc: 0.9522 - f1: 0.9459 - recall: 0.9850 - precision: 0.9101 - val_loss: 0.1122 - val_acc: 0.9533 - val_f1: 0.9474 - val_recall: 0.9924 - val_precision: 0.9068\n",
      "Epoch 13/25\n",
      "2581560/2581560 [==============================] - 20s 8us/step - loss: 0.1172 - acc: 0.9522 - f1: 0.9459 - recall: 0.9849 - precision: 0.9103 - val_loss: 0.1118 - val_acc: 0.9531 - val_f1: 0.9473 - val_recall: 0.9923 - val_precision: 0.9065\n",
      "Epoch 14/25\n",
      "2581560/2581560 [==============================] - 21s 8us/step - loss: 0.1168 - acc: 0.9522 - f1: 0.9459 - recall: 0.9848 - precision: 0.9104 - val_loss: 0.1114 - val_acc: 0.9531 - val_f1: 0.9473 - val_recall: 0.9924 - val_precision: 0.9065\n",
      "Epoch 15/25\n",
      "2581560/2581560 [==============================] - 21s 8us/step - loss: 0.1166 - acc: 0.9525 - f1: 0.9461 - recall: 0.9847 - precision: 0.9109 - val_loss: 0.1113 - val_acc: 0.9534 - val_f1: 0.9475 - val_recall: 0.9923 - val_precision: 0.9071\n",
      "Epoch 16/25\n",
      "2581560/2581560 [==============================] - 21s 8us/step - loss: 0.1166 - acc: 0.9524 - f1: 0.9460 - recall: 0.9846 - precision: 0.9108 - val_loss: 0.1113 - val_acc: 0.9533 - val_f1: 0.9475 - val_recall: 0.9924 - val_precision: 0.9068\n",
      "Epoch 17/25\n",
      "2581560/2581560 [==============================] - 21s 8us/step - loss: 0.1163 - acc: 0.9524 - f1: 0.9461 - recall: 0.9847 - precision: 0.9107 - val_loss: 0.1108 - val_acc: 0.9542 - val_f1: 0.9484 - val_recall: 0.9902 - val_precision: 0.9103\n",
      "Epoch 18/25\n",
      "2581560/2581560 [==============================] - 20s 8us/step - loss: 0.1162 - acc: 0.9523 - f1: 0.9460 - recall: 0.9849 - precision: 0.9105 - val_loss: 0.1110 - val_acc: 0.9532 - val_f1: 0.9473 - val_recall: 0.9925 - val_precision: 0.9065\n",
      "Epoch 19/25\n",
      "2581560/2581560 [==============================] - 20s 8us/step - loss: 0.1161 - acc: 0.9523 - f1: 0.9460 - recall: 0.9848 - precision: 0.9105 - val_loss: 0.1106 - val_acc: 0.9539 - val_f1: 0.9480 - val_recall: 0.9913 - val_precision: 0.9088\n",
      "Epoch 20/25\n",
      "2581560/2581560 [==============================] - 21s 8us/step - loss: 0.1160 - acc: 0.9523 - f1: 0.9460 - recall: 0.9848 - precision: 0.9105 - val_loss: 0.1104 - val_acc: 0.9534 - val_f1: 0.9476 - val_recall: 0.9924 - val_precision: 0.9070\n",
      "Epoch 21/25\n",
      "2581560/2581560 [==============================] - 21s 8us/step - loss: 0.1159 - acc: 0.9525 - f1: 0.9462 - recall: 0.9851 - precision: 0.9106 - val_loss: 0.1103 - val_acc: 0.9539 - val_f1: 0.9480 - val_recall: 0.9914 - val_precision: 0.9086\n",
      "Epoch 22/25\n",
      "2581560/2581560 [==============================] - 21s 8us/step - loss: 0.1157 - acc: 0.9525 - f1: 0.9462 - recall: 0.9852 - precision: 0.9106 - val_loss: 0.1103 - val_acc: 0.9533 - val_f1: 0.9474 - val_recall: 0.9924 - val_precision: 0.9068\n",
      "Epoch 23/25\n",
      "2581560/2581560 [==============================] - 21s 8us/step - loss: 0.1156 - acc: 0.9525 - f1: 0.9462 - recall: 0.9851 - precision: 0.9107 - val_loss: 0.1100 - val_acc: 0.9539 - val_f1: 0.9480 - val_recall: 0.9916 - val_precision: 0.9085\n",
      "Epoch 24/25\n",
      "2581560/2581560 [==============================] - 21s 8us/step - loss: 0.1152 - acc: 0.9526 - f1: 0.9463 - recall: 0.9852 - precision: 0.9108 - val_loss: 0.1101 - val_acc: 0.9534 - val_f1: 0.9476 - val_recall: 0.9924 - val_precision: 0.9070\n",
      "Epoch 25/25\n",
      "2581560/2581560 [==============================] - 20s 8us/step - loss: 0.1151 - acc: 0.9526 - f1: 0.9463 - recall: 0.9852 - precision: 0.9108 - val_loss: 0.1098 - val_acc: 0.9533 - val_f1: 0.9475 - val_recall: 0.9923 - val_precision: 0.9070\n",
      "(2192160, 73)\n",
      "(4071174, 73)\n",
      "dim is 73\n",
      "Train on 2849821 samples, validate on 1221353 samples\n",
      "Epoch 1/25\n",
      "2849821/2849821 [==============================] - 23s 8us/step - loss: 0.1753 - acc: 0.9448 - f1: 0.9452 - recall: 0.9838 - precision: 0.9102 - val_loss: 0.1357 - val_acc: 0.9546 - val_f1: 0.9550 - val_recall: 0.9914 - val_precision: 0.9214\n",
      "Epoch 2/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1394 - acc: 0.9542 - f1: 0.9546 - recall: 0.9919 - precision: 0.9203 - val_loss: 0.1330 - val_acc: 0.9550 - val_f1: 0.9554 - val_recall: 0.9925 - val_precision: 0.9213\n",
      "Epoch 3/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1371 - acc: 0.9545 - f1: 0.9548 - recall: 0.9925 - precision: 0.9203 - val_loss: 0.1318 - val_acc: 0.9551 - val_f1: 0.9555 - val_recall: 0.9928 - val_precision: 0.9212\n",
      "Epoch 4/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1360 - acc: 0.9545 - f1: 0.9549 - recall: 0.9926 - precision: 0.9203 - val_loss: 0.1309 - val_acc: 0.9551 - val_f1: 0.9555 - val_recall: 0.9931 - val_precision: 0.9211\n",
      "Epoch 5/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1350 - acc: 0.9546 - f1: 0.9550 - recall: 0.9928 - precision: 0.9204 - val_loss: 0.1303 - val_acc: 0.9552 - val_f1: 0.9556 - val_recall: 0.9932 - val_precision: 0.9210\n",
      "Epoch 6/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1343 - acc: 0.9549 - f1: 0.9553 - recall: 0.9929 - precision: 0.9207 - val_loss: 0.1300 - val_acc: 0.9552 - val_f1: 0.9556 - val_recall: 0.9933 - val_precision: 0.9210\n",
      "Epoch 7/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1339 - acc: 0.9549 - f1: 0.9553 - recall: 0.9929 - precision: 0.9207 - val_loss: 0.1297 - val_acc: 0.9552 - val_f1: 0.9556 - val_recall: 0.9933 - val_precision: 0.9210\n",
      "Epoch 8/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1334 - acc: 0.9550 - f1: 0.9553 - recall: 0.9930 - precision: 0.9208 - val_loss: 0.1291 - val_acc: 0.9552 - val_f1: 0.9556 - val_recall: 0.9935 - val_precision: 0.9208\n",
      "Epoch 9/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1332 - acc: 0.9550 - f1: 0.9554 - recall: 0.9930 - precision: 0.9208 - val_loss: 0.1291 - val_acc: 0.9553 - val_f1: 0.9557 - val_recall: 0.9936 - val_precision: 0.9209\n",
      "Epoch 10/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1329 - acc: 0.9550 - f1: 0.9554 - recall: 0.9930 - precision: 0.9208 - val_loss: 0.1288 - val_acc: 0.9553 - val_f1: 0.9557 - val_recall: 0.9936 - val_precision: 0.9209\n",
      "Epoch 11/25\n",
      "2849821/2849821 [==============================] - 21s 7us/step - loss: 0.1326 - acc: 0.9550 - f1: 0.9554 - recall: 0.9930 - precision: 0.9208 - val_loss: 0.1285 - val_acc: 0.9553 - val_f1: 0.9558 - val_recall: 0.9936 - val_precision: 0.9210\n",
      "Epoch 12/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1324 - acc: 0.9550 - f1: 0.9554 - recall: 0.9930 - precision: 0.9208 - val_loss: 0.1285 - val_acc: 0.9554 - val_f1: 0.9558 - val_recall: 0.9936 - val_precision: 0.9210\n",
      "Epoch 13/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1323 - acc: 0.9550 - f1: 0.9554 - recall: 0.9930 - precision: 0.9208 - val_loss: 0.1282 - val_acc: 0.9554 - val_f1: 0.9558 - val_recall: 0.9937 - val_precision: 0.9210\n",
      "Epoch 14/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1321 - acc: 0.9550 - f1: 0.9554 - recall: 0.9930 - precision: 0.9208 - val_loss: 0.1281 - val_acc: 0.9558 - val_f1: 0.9561 - val_recall: 0.9927 - val_precision: 0.9225\n",
      "Epoch 15/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1320 - acc: 0.9550 - f1: 0.9554 - recall: 0.9930 - precision: 0.9209 - val_loss: 0.1278 - val_acc: 0.9555 - val_f1: 0.9560 - val_recall: 0.9937 - val_precision: 0.9213\n",
      "Epoch 16/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1319 - acc: 0.9550 - f1: 0.9554 - recall: 0.9930 - precision: 0.9209 - val_loss: 0.1279 - val_acc: 0.9556 - val_f1: 0.9560 - val_recall: 0.9936 - val_precision: 0.9214\n",
      "Epoch 17/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1318 - acc: 0.9550 - f1: 0.9554 - recall: 0.9930 - precision: 0.9209 - val_loss: 0.1276 - val_acc: 0.9555 - val_f1: 0.9559 - val_recall: 0.9937 - val_precision: 0.9213\n",
      "Epoch 18/25\n",
      "2849821/2849821 [==============================] - 23s 8us/step - loss: 0.1314 - acc: 0.9551 - f1: 0.9555 - recall: 0.9930 - precision: 0.9210 - val_loss: 0.1275 - val_acc: 0.9559 - val_f1: 0.9562 - val_recall: 0.9931 - val_precision: 0.9223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1316 - acc: 0.9550 - f1: 0.9554 - recall: 0.9930 - precision: 0.9209 - val_loss: 0.1273 - val_acc: 0.9556 - val_f1: 0.9560 - val_recall: 0.9936 - val_precision: 0.9214\n",
      "Epoch 20/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1313 - acc: 0.9551 - f1: 0.9555 - recall: 0.9929 - precision: 0.9211 - val_loss: 0.1270 - val_acc: 0.9556 - val_f1: 0.9560 - val_recall: 0.9937 - val_precision: 0.9214\n",
      "Epoch 21/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1311 - acc: 0.9551 - f1: 0.9555 - recall: 0.9930 - precision: 0.9210 - val_loss: 0.1268 - val_acc: 0.9557 - val_f1: 0.9561 - val_recall: 0.9937 - val_precision: 0.9215\n",
      "Epoch 22/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1310 - acc: 0.9551 - f1: 0.9555 - recall: 0.9930 - precision: 0.9210 - val_loss: 0.1268 - val_acc: 0.9557 - val_f1: 0.9561 - val_recall: 0.9937 - val_precision: 0.9215\n",
      "Epoch 23/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1310 - acc: 0.9551 - f1: 0.9555 - recall: 0.9930 - precision: 0.9210 - val_loss: 0.1266 - val_acc: 0.9556 - val_f1: 0.9561 - val_recall: 0.9937 - val_precision: 0.9214\n",
      "Epoch 24/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1307 - acc: 0.9552 - f1: 0.9555 - recall: 0.9929 - precision: 0.9212 - val_loss: 0.1264 - val_acc: 0.9557 - val_f1: 0.9561 - val_recall: 0.9937 - val_precision: 0.9216\n",
      "Epoch 25/25\n",
      "2849821/2849821 [==============================] - 22s 8us/step - loss: 0.1306 - acc: 0.9552 - f1: 0.9555 - recall: 0.9929 - precision: 0.9211 - val_loss: 0.1263 - val_acc: 0.9557 - val_f1: 0.9561 - val_recall: 0.9937 - val_precision: 0.9216\n",
      "(1270531, 73)\n",
      "(3120512, 72)\n",
      "dim is 72\n",
      "Train on 2184358 samples, validate on 936154 samples\n",
      "Epoch 1/25\n",
      "2184358/2184358 [==============================] - 17s 8us/step - loss: 0.1990 - acc: 0.9341 - f1: 0.9481 - recall: 0.9841 - precision: 0.9151 - val_loss: 0.1488 - val_acc: 0.9465 - val_f1: 0.9577 - val_recall: 0.9926 - val_precision: 0.9255\n",
      "Epoch 2/25\n",
      "2184358/2184358 [==============================] - 17s 8us/step - loss: 0.1518 - acc: 0.9467 - f1: 0.9579 - recall: 0.9933 - precision: 0.9251 - val_loss: 0.1453 - val_acc: 0.9472 - val_f1: 0.9583 - val_recall: 0.9940 - val_precision: 0.9253\n",
      "Epoch 3/25\n",
      "2184358/2184358 [==============================] - 17s 8us/step - loss: 0.1492 - acc: 0.9471 - f1: 0.9582 - recall: 0.9937 - precision: 0.9254 - val_loss: 0.1435 - val_acc: 0.9470 - val_f1: 0.9582 - val_recall: 0.9939 - val_precision: 0.9252\n",
      "Epoch 4/25\n",
      "2184358/2184358 [==============================] - 17s 8us/step - loss: 0.1479 - acc: 0.9474 - f1: 0.9584 - recall: 0.9938 - precision: 0.9257 - val_loss: 0.1425 - val_acc: 0.9476 - val_f1: 0.9586 - val_recall: 0.9938 - val_precision: 0.9261\n",
      "Epoch 5/25\n",
      "2184358/2184358 [==============================] - 17s 8us/step - loss: 0.1469 - acc: 0.9475 - f1: 0.9585 - recall: 0.9937 - precision: 0.9260 - val_loss: 0.1415 - val_acc: 0.9476 - val_f1: 0.9586 - val_recall: 0.9938 - val_precision: 0.9262\n",
      "Epoch 6/25\n",
      "2184358/2184358 [==============================] - 17s 8us/step - loss: 0.1462 - acc: 0.9476 - f1: 0.9586 - recall: 0.9936 - precision: 0.9262 - val_loss: 0.1408 - val_acc: 0.9477 - val_f1: 0.9587 - val_recall: 0.9938 - val_precision: 0.9262\n",
      "Epoch 7/25\n",
      "2184358/2184358 [==============================] - 17s 8us/step - loss: 0.1454 - acc: 0.9477 - f1: 0.9587 - recall: 0.9937 - precision: 0.9263 - val_loss: 0.1400 - val_acc: 0.9479 - val_f1: 0.9588 - val_recall: 0.9942 - val_precision: 0.9262\n",
      "Epoch 8/25\n",
      "2184358/2184358 [==============================] - 17s 8us/step - loss: 0.1447 - acc: 0.9478 - f1: 0.9587 - recall: 0.9935 - precision: 0.9265 - val_loss: 0.1395 - val_acc: 0.9480 - val_f1: 0.9590 - val_recall: 0.9945 - val_precision: 0.9262\n",
      "Epoch 9/25\n",
      "2184358/2184358 [==============================] - 18s 8us/step - loss: 0.1444 - acc: 0.9479 - f1: 0.9588 - recall: 0.9936 - precision: 0.9266 - val_loss: 0.1389 - val_acc: 0.9480 - val_f1: 0.9590 - val_recall: 0.9945 - val_precision: 0.9261\n",
      "Epoch 10/25\n",
      "2184358/2184358 [==============================] - 17s 8us/step - loss: 0.1439 - acc: 0.9480 - f1: 0.9588 - recall: 0.9935 - precision: 0.9267 - val_loss: 0.1385 - val_acc: 0.9480 - val_f1: 0.9589 - val_recall: 0.9943 - val_precision: 0.9262\n",
      "Epoch 11/25\n",
      "2184358/2184358 [==============================] - 17s 8us/step - loss: 0.1437 - acc: 0.9480 - f1: 0.9589 - recall: 0.9935 - precision: 0.9268 - val_loss: 0.1380 - val_acc: 0.9484 - val_f1: 0.9592 - val_recall: 0.9939 - val_precision: 0.9272\n",
      "Epoch 12/25\n",
      "2184358/2184358 [==============================] - 17s 8us/step - loss: 0.1432 - acc: 0.9481 - f1: 0.9589 - recall: 0.9935 - precision: 0.9269 - val_loss: 0.1378 - val_acc: 0.9480 - val_f1: 0.9589 - val_recall: 0.9944 - val_precision: 0.9262\n",
      "Epoch 13/25\n",
      "2184358/2184358 [==============================] - 17s 8us/step - loss: 0.1429 - acc: 0.9482 - f1: 0.9590 - recall: 0.9936 - precision: 0.9270 - val_loss: 0.1375 - val_acc: 0.9486 - val_f1: 0.9594 - val_recall: 0.9942 - val_precision: 0.9271\n",
      "Epoch 14/25\n",
      "2184358/2184358 [==============================] - 17s 8us/step - loss: 0.1425 - acc: 0.9482 - f1: 0.9590 - recall: 0.9935 - precision: 0.9270 - val_loss: 0.1371 - val_acc: 0.9488 - val_f1: 0.9595 - val_recall: 0.9942 - val_precision: 0.9274\n",
      "Epoch 15/25\n",
      "2184358/2184358 [==============================] - 16s 8us/step - loss: 0.1426 - acc: 0.9482 - f1: 0.9590 - recall: 0.9935 - precision: 0.9271 - val_loss: 0.1371 - val_acc: 0.9482 - val_f1: 0.9591 - val_recall: 0.9943 - val_precision: 0.9266\n",
      "Epoch 16/25\n",
      "2184358/2184358 [==============================] - 17s 8us/step - loss: 0.1423 - acc: 0.9483 - f1: 0.9591 - recall: 0.9936 - precision: 0.9272 - val_loss: 0.1369 - val_acc: 0.9486 - val_f1: 0.9594 - val_recall: 0.9942 - val_precision: 0.9272\n",
      "Epoch 17/25\n",
      "2184358/2184358 [==============================] - 16s 8us/step - loss: 0.1421 - acc: 0.9482 - f1: 0.9590 - recall: 0.9934 - precision: 0.9271 - val_loss: 0.1368 - val_acc: 0.9489 - val_f1: 0.9596 - val_recall: 0.9943 - val_precision: 0.9276\n",
      "Epoch 18/25\n",
      "2184358/2184358 [==============================] - 16s 7us/step - loss: 0.1420 - acc: 0.9483 - f1: 0.9591 - recall: 0.9935 - precision: 0.9272 - val_loss: 0.1367 - val_acc: 0.9493 - val_f1: 0.9599 - val_recall: 0.9939 - val_precision: 0.9285\n",
      "Epoch 19/25\n",
      "2184358/2184358 [==============================] - 17s 8us/step - loss: 0.1419 - acc: 0.9483 - f1: 0.9591 - recall: 0.9936 - precision: 0.9272 - val_loss: 0.1364 - val_acc: 0.9489 - val_f1: 0.9596 - val_recall: 0.9940 - val_precision: 0.9277\n",
      "Epoch 20/25\n",
      "2184358/2184358 [==============================] - 16s 8us/step - loss: 0.1417 - acc: 0.9483 - f1: 0.9591 - recall: 0.9935 - precision: 0.9273 - val_loss: 0.1364 - val_acc: 0.9493 - val_f1: 0.9599 - val_recall: 0.9936 - val_precision: 0.9287\n",
      "Epoch 21/25\n",
      "2184358/2184358 [==============================] - 16s 7us/step - loss: 0.1416 - acc: 0.9483 - f1: 0.9591 - recall: 0.9934 - precision: 0.9273 - val_loss: 0.1364 - val_acc: 0.9485 - val_f1: 0.9594 - val_recall: 0.9951 - val_precision: 0.9264\n",
      "Epoch 22/25\n",
      "2184358/2184358 [==============================] - 15s 7us/step - loss: 0.1416 - acc: 0.9483 - f1: 0.9591 - recall: 0.9934 - precision: 0.9273 - val_loss: 0.1363 - val_acc: 0.9489 - val_f1: 0.9596 - val_recall: 0.9942 - val_precision: 0.9276\n",
      "Epoch 23/25\n",
      "2184358/2184358 [==============================] - 17s 8us/step - loss: 0.1415 - acc: 0.9484 - f1: 0.9592 - recall: 0.9935 - precision: 0.9274 - val_loss: 0.1361 - val_acc: 0.9494 - val_f1: 0.9599 - val_recall: 0.9935 - val_precision: 0.9288\n",
      "Epoch 24/25\n",
      "2184358/2184358 [==============================] - 17s 8us/step - loss: 0.1414 - acc: 0.9483 - f1: 0.9591 - recall: 0.9933 - precision: 0.9274 - val_loss: 0.1360 - val_acc: 0.9492 - val_f1: 0.9598 - val_recall: 0.9933 - val_precision: 0.9287\n",
      "Epoch 25/25\n",
      "2184358/2184358 [==============================] - 18s 8us/step - loss: 0.1413 - acc: 0.9484 - f1: 0.9591 - recall: 0.9933 - precision: 0.9274 - val_loss: 0.1360 - val_acc: 0.9493 - val_f1: 0.9599 - val_recall: 0.9935 - val_precision: 0.9287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1247894, 72)\n",
      "(2641796, 73)\n",
      "dim is 73\n",
      "Train on 1849257 samples, validate on 792539 samples\n",
      "Epoch 1/25\n",
      "1849257/1849257 [==============================] - 16s 9us/step - loss: 0.1833 - acc: 0.9333 - f1: 0.9415 - recall: 0.9755 - precision: 0.9106 - val_loss: 0.1264 - val_acc: 0.9464 - val_f1: 0.9525 - val_recall: 0.9802 - val_precision: 0.9267\n",
      "Epoch 2/25\n",
      "1849257/1849257 [==============================] - 16s 9us/step - loss: 0.1288 - acc: 0.9471 - f1: 0.9531 - recall: 0.9809 - precision: 0.9271 - val_loss: 0.1227 - val_acc: 0.9471 - val_f1: 0.9532 - val_recall: 0.9817 - val_precision: 0.9265\n",
      "Epoch 3/25\n",
      "1849257/1849257 [==============================] - 16s 9us/step - loss: 0.1261 - acc: 0.9477 - f1: 0.9537 - recall: 0.9818 - precision: 0.9274 - val_loss: 0.1214 - val_acc: 0.9483 - val_f1: 0.9542 - val_recall: 0.9812 - val_precision: 0.9289\n",
      "Epoch 4/25\n",
      "1849257/1849257 [==============================] - 16s 9us/step - loss: 0.1248 - acc: 0.9480 - f1: 0.9539 - recall: 0.9817 - precision: 0.9280 - val_loss: 0.1202 - val_acc: 0.9485 - val_f1: 0.9543 - val_recall: 0.9814 - val_precision: 0.9290\n",
      "Epoch 5/25\n",
      "1849257/1849257 [==============================] - 16s 9us/step - loss: 0.1238 - acc: 0.9482 - f1: 0.9541 - recall: 0.9815 - precision: 0.9284 - val_loss: 0.1193 - val_acc: 0.9486 - val_f1: 0.9545 - val_recall: 0.9816 - val_precision: 0.9291\n",
      "Epoch 6/25\n",
      "1849257/1849257 [==============================] - 16s 9us/step - loss: 0.1230 - acc: 0.9483 - f1: 0.9542 - recall: 0.9813 - precision: 0.9288 - val_loss: 0.1186 - val_acc: 0.9488 - val_f1: 0.9546 - val_recall: 0.9813 - val_precision: 0.9296\n",
      "Epoch 7/25\n",
      "1849257/1849257 [==============================] - 16s 9us/step - loss: 0.1224 - acc: 0.9483 - f1: 0.9542 - recall: 0.9812 - precision: 0.9289 - val_loss: 0.1180 - val_acc: 0.9492 - val_f1: 0.9549 - val_recall: 0.9825 - val_precision: 0.9292\n",
      "Epoch 8/25\n",
      "1849257/1849257 [==============================] - 15s 8us/step - loss: 0.1218 - acc: 0.9486 - f1: 0.9543 - recall: 0.9810 - precision: 0.9294 - val_loss: 0.1174 - val_acc: 0.9493 - val_f1: 0.9550 - val_recall: 0.9827 - val_precision: 0.9292\n",
      "Epoch 9/25\n",
      "1849257/1849257 [==============================] - 16s 8us/step - loss: 0.1213 - acc: 0.9488 - f1: 0.9545 - recall: 0.9813 - precision: 0.9295 - val_loss: 0.1171 - val_acc: 0.9496 - val_f1: 0.9553 - val_recall: 0.9828 - val_precision: 0.9296\n",
      "Epoch 10/25\n",
      "1849257/1849257 [==============================] - 16s 9us/step - loss: 0.1209 - acc: 0.9488 - f1: 0.9546 - recall: 0.9813 - precision: 0.9296 - val_loss: 0.1167 - val_acc: 0.9495 - val_f1: 0.9552 - val_recall: 0.9827 - val_precision: 0.9295\n",
      "Epoch 11/25\n",
      "1849257/1849257 [==============================] - 16s 9us/step - loss: 0.1207 - acc: 0.9490 - f1: 0.9547 - recall: 0.9815 - precision: 0.9296 - val_loss: 0.1165 - val_acc: 0.9500 - val_f1: 0.9557 - val_recall: 0.9839 - val_precision: 0.9294\n",
      "Epoch 12/25\n",
      "1849257/1849257 [==============================] - 16s 9us/step - loss: 0.1203 - acc: 0.9489 - f1: 0.9547 - recall: 0.9817 - precision: 0.9295 - val_loss: 0.1162 - val_acc: 0.9503 - val_f1: 0.9560 - val_recall: 0.9849 - val_precision: 0.9290\n",
      "Epoch 13/25\n",
      "1849257/1849257 [==============================] - 16s 9us/step - loss: 0.1202 - acc: 0.9492 - f1: 0.9549 - recall: 0.9819 - precision: 0.9296 - val_loss: 0.1157 - val_acc: 0.9500 - val_f1: 0.9557 - val_recall: 0.9835 - val_precision: 0.9298\n",
      "Epoch 14/25\n",
      "1849257/1849257 [==============================] - 17s 9us/step - loss: 0.1198 - acc: 0.9491 - f1: 0.9549 - recall: 0.9822 - precision: 0.9294 - val_loss: 0.1156 - val_acc: 0.9503 - val_f1: 0.9560 - val_recall: 0.9846 - val_precision: 0.9292\n",
      "Epoch 15/25\n",
      "1849257/1849257 [==============================] - 16s 9us/step - loss: 0.1196 - acc: 0.9493 - f1: 0.9550 - recall: 0.9824 - precision: 0.9295 - val_loss: 0.1154 - val_acc: 0.9501 - val_f1: 0.9558 - val_recall: 0.9835 - val_precision: 0.9298\n",
      "Epoch 16/25\n",
      "1849257/1849257 [==============================] - 16s 8us/step - loss: 0.1193 - acc: 0.9494 - f1: 0.9551 - recall: 0.9823 - precision: 0.9297 - val_loss: 0.1153 - val_acc: 0.9505 - val_f1: 0.9562 - val_recall: 0.9852 - val_precision: 0.9290\n",
      "Epoch 17/25\n",
      "1849257/1849257 [==============================] - 16s 9us/step - loss: 0.1191 - acc: 0.9495 - f1: 0.9552 - recall: 0.9826 - precision: 0.9296 - val_loss: 0.1150 - val_acc: 0.9502 - val_f1: 0.9559 - val_recall: 0.9840 - val_precision: 0.9296\n",
      "Epoch 18/25\n",
      "1849257/1849257 [==============================] - 17s 9us/step - loss: 0.1191 - acc: 0.9495 - f1: 0.9552 - recall: 0.9827 - precision: 0.9296 - val_loss: 0.1150 - val_acc: 0.9504 - val_f1: 0.9561 - val_recall: 0.9852 - val_precision: 0.9290\n",
      "Epoch 19/25\n",
      "1849257/1849257 [==============================] - 17s 9us/step - loss: 0.1189 - acc: 0.9496 - f1: 0.9553 - recall: 0.9826 - precision: 0.9297 - val_loss: 0.1147 - val_acc: 0.9504 - val_f1: 0.9562 - val_recall: 0.9856 - val_precision: 0.9287\n",
      "Epoch 20/25\n",
      "1849257/1849257 [==============================] - 17s 9us/step - loss: 0.1188 - acc: 0.9496 - f1: 0.9553 - recall: 0.9829 - precision: 0.9295 - val_loss: 0.1145 - val_acc: 0.9502 - val_f1: 0.9559 - val_recall: 0.9838 - val_precision: 0.9298\n",
      "Epoch 21/25\n",
      "1849257/1849257 [==============================] - 15s 8us/step - loss: 0.1188 - acc: 0.9495 - f1: 0.9552 - recall: 0.9826 - precision: 0.9296 - val_loss: 0.1145 - val_acc: 0.9504 - val_f1: 0.9560 - val_recall: 0.9846 - val_precision: 0.9294\n",
      "Epoch 22/25\n",
      "1849257/1849257 [==============================] - 17s 9us/step - loss: 0.1185 - acc: 0.9497 - f1: 0.9554 - recall: 0.9826 - precision: 0.9299 - val_loss: 0.1144 - val_acc: 0.9502 - val_f1: 0.9559 - val_recall: 0.9837 - val_precision: 0.9299\n",
      "Epoch 23/25\n",
      "1849257/1849257 [==============================] - 16s 9us/step - loss: 0.1184 - acc: 0.9498 - f1: 0.9555 - recall: 0.9827 - precision: 0.9299 - val_loss: 0.1142 - val_acc: 0.9505 - val_f1: 0.9561 - val_recall: 0.9851 - val_precision: 0.9291\n",
      "Epoch 24/25\n",
      "1849257/1849257 [==============================] - 16s 9us/step - loss: 0.1183 - acc: 0.9497 - f1: 0.9554 - recall: 0.9828 - precision: 0.9298 - val_loss: 0.1142 - val_acc: 0.9505 - val_f1: 0.9562 - val_recall: 0.9855 - val_precision: 0.9289\n",
      "Epoch 25/25\n",
      "1849257/1849257 [==============================] - 16s 9us/step - loss: 0.1182 - acc: 0.9498 - f1: 0.9555 - recall: 0.9828 - precision: 0.9299 - val_loss: 0.1139 - val_acc: 0.9504 - val_f1: 0.9561 - val_recall: 0.9848 - val_precision: 0.9293\n",
      "(1606839, 73)\n",
      "(2890301, 73)\n",
      "dim is 73\n",
      "Train on 2023210 samples, validate on 867091 samples\n",
      "Epoch 1/25\n",
      "2023210/2023210 [==============================] - 18s 9us/step - loss: 0.1937 - acc: 0.9309 - f1: 0.9306 - recall: 0.9808 - precision: 0.8862 - val_loss: 0.1351 - val_acc: 0.9446 - val_f1: 0.9434 - val_recall: 0.9848 - val_precision: 0.9057\n",
      "Epoch 2/25\n",
      "2023210/2023210 [==============================] - 17s 9us/step - loss: 0.1386 - acc: 0.9451 - f1: 0.9437 - recall: 0.9822 - precision: 0.9085 - val_loss: 0.1299 - val_acc: 0.9462 - val_f1: 0.9449 - val_recall: 0.9840 - val_precision: 0.9092\n",
      "Epoch 3/25\n",
      "2023210/2023210 [==============================] - 17s 8us/step - loss: 0.1351 - acc: 0.9463 - f1: 0.9448 - recall: 0.9813 - precision: 0.9113 - val_loss: 0.1279 - val_acc: 0.9480 - val_f1: 0.9465 - val_recall: 0.9822 - val_precision: 0.9137\n",
      "Epoch 4/25\n",
      "2023210/2023210 [==============================] - 17s 8us/step - loss: 0.1334 - acc: 0.9469 - f1: 0.9454 - recall: 0.9806 - precision: 0.9129 - val_loss: 0.1265 - val_acc: 0.9482 - val_f1: 0.9467 - val_recall: 0.9828 - val_precision: 0.9136\n",
      "Epoch 5/25\n",
      "2023210/2023210 [==============================] - 16s 8us/step - loss: 0.1324 - acc: 0.9470 - f1: 0.9455 - recall: 0.9797 - precision: 0.9140 - val_loss: 0.1256 - val_acc: 0.9485 - val_f1: 0.9471 - val_recall: 0.9839 - val_precision: 0.9134\n",
      "Epoch 6/25\n",
      "2023210/2023210 [==============================] - 16s 8us/step - loss: 0.1315 - acc: 0.9473 - f1: 0.9457 - recall: 0.9794 - precision: 0.9146 - val_loss: 0.1248 - val_acc: 0.9487 - val_f1: 0.9474 - val_recall: 0.9848 - val_precision: 0.9131\n",
      "Epoch 7/25\n",
      "2023210/2023210 [==============================] - 16s 8us/step - loss: 0.1309 - acc: 0.9476 - f1: 0.9460 - recall: 0.9791 - precision: 0.9154 - val_loss: 0.1240 - val_acc: 0.9487 - val_f1: 0.9473 - val_recall: 0.9840 - val_precision: 0.9136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25\n",
      "2023210/2023210 [==============================] - 16s 8us/step - loss: 0.1302 - acc: 0.9477 - f1: 0.9461 - recall: 0.9789 - precision: 0.9158 - val_loss: 0.1233 - val_acc: 0.9491 - val_f1: 0.9478 - val_recall: 0.9853 - val_precision: 0.9134\n",
      "Epoch 9/25\n",
      "2023210/2023210 [==============================] - 17s 8us/step - loss: 0.1295 - acc: 0.9478 - f1: 0.9462 - recall: 0.9790 - precision: 0.9159 - val_loss: 0.1228 - val_acc: 0.9490 - val_f1: 0.9476 - val_recall: 0.9847 - val_precision: 0.9136\n",
      "Epoch 10/25\n",
      "2023210/2023210 [==============================] - 17s 8us/step - loss: 0.1288 - acc: 0.9479 - f1: 0.9463 - recall: 0.9792 - precision: 0.9159 - val_loss: 0.1224 - val_acc: 0.9491 - val_f1: 0.9477 - val_recall: 0.9851 - val_precision: 0.9135\n",
      "Epoch 11/25\n",
      "2023210/2023210 [==============================] - 17s 8us/step - loss: 0.1286 - acc: 0.9480 - f1: 0.9464 - recall: 0.9792 - precision: 0.9162 - val_loss: 0.1219 - val_acc: 0.9491 - val_f1: 0.9477 - val_recall: 0.9846 - val_precision: 0.9138\n",
      "Epoch 12/25\n",
      "2023210/2023210 [==============================] - 16s 8us/step - loss: 0.1283 - acc: 0.9481 - f1: 0.9465 - recall: 0.9792 - precision: 0.9163 - val_loss: 0.1215 - val_acc: 0.9491 - val_f1: 0.9477 - val_recall: 0.9848 - val_precision: 0.9138\n",
      "Epoch 13/25\n",
      "2023210/2023210 [==============================] - 17s 8us/step - loss: 0.1279 - acc: 0.9481 - f1: 0.9465 - recall: 0.9789 - precision: 0.9165 - val_loss: 0.1213 - val_acc: 0.9492 - val_f1: 0.9479 - val_recall: 0.9854 - val_precision: 0.9135\n",
      "Epoch 14/25\n",
      "2023210/2023210 [==============================] - 17s 8us/step - loss: 0.1277 - acc: 0.9482 - f1: 0.9465 - recall: 0.9791 - precision: 0.9164 - val_loss: 0.1210 - val_acc: 0.9492 - val_f1: 0.9479 - val_recall: 0.9855 - val_precision: 0.9134\n",
      "Epoch 15/25\n",
      "2023210/2023210 [==============================] - 16s 8us/step - loss: 0.1273 - acc: 0.9482 - f1: 0.9465 - recall: 0.9789 - precision: 0.9166 - val_loss: 0.1208 - val_acc: 0.9493 - val_f1: 0.9479 - val_recall: 0.9854 - val_precision: 0.9136\n",
      "Epoch 16/25\n",
      "2023210/2023210 [==============================] - 16s 8us/step - loss: 0.1270 - acc: 0.9482 - f1: 0.9466 - recall: 0.9790 - precision: 0.9166 - val_loss: 0.1204 - val_acc: 0.9494 - val_f1: 0.9480 - val_recall: 0.9858 - val_precision: 0.9135\n",
      "Epoch 17/25\n",
      "2023210/2023210 [==============================] - 16s 8us/step - loss: 0.1269 - acc: 0.9483 - f1: 0.9466 - recall: 0.9789 - precision: 0.9168 - val_loss: 0.1201 - val_acc: 0.9494 - val_f1: 0.9481 - val_recall: 0.9856 - val_precision: 0.9137\n",
      "Epoch 18/25\n",
      "2023210/2023210 [==============================] - 15s 8us/step - loss: 0.1267 - acc: 0.9482 - f1: 0.9466 - recall: 0.9789 - precision: 0.9167 - val_loss: 0.1200 - val_acc: 0.9494 - val_f1: 0.9480 - val_recall: 0.9853 - val_precision: 0.9139\n",
      "Epoch 19/25\n",
      "2023210/2023210 [==============================] - 16s 8us/step - loss: 0.1264 - acc: 0.9483 - f1: 0.9466 - recall: 0.9786 - precision: 0.9170 - val_loss: 0.1198 - val_acc: 0.9496 - val_f1: 0.9483 - val_recall: 0.9857 - val_precision: 0.9140\n",
      "Epoch 20/25\n",
      "2023210/2023210 [==============================] - 16s 8us/step - loss: 0.1264 - acc: 0.9482 - f1: 0.9466 - recall: 0.9787 - precision: 0.9169 - val_loss: 0.1195 - val_acc: 0.9495 - val_f1: 0.9482 - val_recall: 0.9853 - val_precision: 0.9141\n",
      "Epoch 21/25\n",
      "2023210/2023210 [==============================] - 16s 8us/step - loss: 0.1261 - acc: 0.9482 - f1: 0.9466 - recall: 0.9785 - precision: 0.9170 - val_loss: 0.1194 - val_acc: 0.9500 - val_f1: 0.9485 - val_recall: 0.9819 - val_precision: 0.9176\n",
      "Epoch 22/25\n",
      "2023210/2023210 [==============================] - 16s 8us/step - loss: 0.1261 - acc: 0.9482 - f1: 0.9466 - recall: 0.9786 - precision: 0.9170 - val_loss: 0.1193 - val_acc: 0.9496 - val_f1: 0.9483 - val_recall: 0.9858 - val_precision: 0.9140\n",
      "Epoch 23/25\n",
      "2023210/2023210 [==============================] - 16s 8us/step - loss: 0.1260 - acc: 0.9482 - f1: 0.9466 - recall: 0.9784 - precision: 0.9171 - val_loss: 0.1193 - val_acc: 0.9496 - val_f1: 0.9480 - val_recall: 0.9790 - val_precision: 0.9192\n",
      "Epoch 24/25\n",
      "2023210/2023210 [==============================] - 16s 8us/step - loss: 0.1257 - acc: 0.9478 - f1: 0.9461 - recall: 0.9783 - precision: 0.9164 - val_loss: 0.1191 - val_acc: 0.9496 - val_f1: 0.9483 - val_recall: 0.9859 - val_precision: 0.9139\n",
      "Epoch 25/25\n",
      "2023210/2023210 [==============================] - 17s 8us/step - loss: 0.1256 - acc: 0.9476 - f1: 0.9460 - recall: 0.9787 - precision: 0.9158 - val_loss: 0.1190 - val_acc: 0.9497 - val_f1: 0.9484 - val_recall: 0.9860 - val_precision: 0.9139\n",
      "(2150309, 73)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=16)) as sess:\n",
    "    K.set_session(sess)\n",
    "    for train, test in zip(trainPath, testPath):\n",
    "\n",
    "        #drop different port numbers\n",
    "        df_train = pd.read_csv(train)\n",
    "        temp1 = set(df_train.columns)\n",
    "\n",
    "        #for test in testPath:\n",
    "        df_test = pd.read_csv(test)\n",
    "        temp2 = set(df_test.columns)\n",
    "\n",
    "        df_train = df_train.drop(list(temp1 - temp2), axis = 1)\n",
    "        df_test = df_test.drop(list(temp2 - temp1), axis = 1)\n",
    "\n",
    "\n",
    "        X, y = prepare(df_train)\n",
    "        dim = X.shape[1]\n",
    "        print('dim is %s'%dim)\n",
    "\n",
    "        model = models.Sequential()\n",
    "        model.add(Dense(dim//2, input_dim = dim, kernel_initializer='uniform', activation='relu'))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "        adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0000002, amsgrad=False)\n",
    "        #sgd = optimizers.sgd(lr=0.0005, momentum=0.5, decay=0.000002, nesterov=False)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',f1,recall,precision])\n",
    "\n",
    "\n",
    "        result = model.fit(X, y, epochs=25, batch_size=256, validation_split=0.3) \n",
    "\n",
    "\n",
    "\n",
    "        X_test, y_test = prepare(df_test)\n",
    "        y_pred = model.predict(X_test).tolist()\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        temp = [1 if x[1]>0.8 else 0 for x in y_pred]\n",
    "        cm= confusion_matrix(y_test, temp)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        precision=tp/(tp+fp)\n",
    "        recall=tp/(tp+fn)\n",
    "        fpr = fp/(fp+ tn)\n",
    "        accuracy = (tp + tn)/(tn + tp + fn + fp)\n",
    "        F1 = 2 * (precision * recall) / (precision + recall)\n",
    "        print(\"precision:\", precision*100)\n",
    "        print(\"recall:\", recall*100)\n",
    "        print(\"false positive rate:\", fpr*100)\n",
    "        print(\"accuracy\",  accuracy*100)\n",
    "        print(\"F1-score\", F1)\n",
    "        '''\n",
    "        \n",
    "        pd.DataFrame([round(x[0], 6) for x in y_pred]).to_csv('/scratch/by8jj/stratified samples/test of test/ann/' + train[-12:-4] + '-' + test[-11:-4] + '.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 1.6, PyTorch 0.4, Keras",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
